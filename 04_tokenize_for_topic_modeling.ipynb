{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import spacy\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('_outputs/harassement_clean_french_no_bots.pickle')\n",
    "df = pd.read_pickle('_outputs/harassement_clean_french_no_bots_transports.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_pos_tags = [\"PROP\",\"DET\",\"PART\",\"CCONJ\",\"ADP\",\"PRON\",\"VERB\",\"ADJ\"]\n",
    "noisy_pos_tags = [\"PROP\",\"DET\",\"PART\",\"CCONJ\",\"ADP\",\"PRON\"]\n",
    "MIN_TOKEN_LENGTH = 3 # minimum token length to remove\n",
    "MIN_WORDS_NUMBER = 10 # minimum of words\n",
    "\n",
    "# Importe le corpus Français\n",
    "import fr_core_news_sm\n",
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noise(token):\n",
    "    '''\n",
    "    standard way to validate spacy tokens\n",
    "    This method validate all the passed tokens and set true false on it\n",
    "    '''\n",
    "    is_noise = False\n",
    "    if token.pos_ in noisy_pos_tags:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_stop == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_digit == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_punct == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_space == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_alpha == False:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif len(token.string) <= MIN_TOKEN_LENGTH:\n",
    "        is_noise = True\n",
    "        \n",
    "    return is_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_stop_words = get_stop_words('fr')\n",
    "for stop in fr_stop_words:\n",
    "    nlp.vocab[stop].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarque : c'est déjà partiellement nettoyé dans 01_clean_text\n",
    "# je garde pour la \"portabilité\" des fonctions\n",
    "def remove_specific_stop(words):\n",
    "    my_stop_words = ['balance', 'ton', 'porc', 'metoo', 'balancetonporc', 'via', 'hashtag', 'too', 'html', 'php', 'the', 'and', 'this', 'new', 'news']\n",
    "    for bad in my_stop_words:\n",
    "        words = words.replace(bad, ' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "index = 1\n",
    "for index, row in df.iterrows():\n",
    "    article = []\n",
    "    if index%10000 == 0:\n",
    "        print(index) # pour voir où cela en est\n",
    "    index += 1\n",
    "    words = row['clean_text']\n",
    "    words = remove_specific_stop(words)\n",
    "    if(len(words.split()) >= MIN_WORDS_NUMBER): # Only tweets with at least 10 words\n",
    "        nlp_words = nlp(words)\n",
    "        for word in nlp_words:\n",
    "            if not is_noise(word):\n",
    "                article.append(word.lemma_)\n",
    "        texts.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"_outputs/tokens.pickle\", \"wb\") as fp:\n",
    "with open(\"_outputs/tokens_transports.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['remonter',\n",
       "  'manif',\n",
       "  'immense',\n",
       "  'olala',\n",
       "  'mettre',\n",
       "  'vie',\n",
       "  'remonter',\n",
       "  'aller',\n",
       "  'gare',\n",
       "  'peyrou',\n",
       "  'montage',\n",
       "  'mur',\n",
       "  'tribunal'],\n",
       " ['toucher',\n",
       "  'métro',\n",
       "  'rue',\n",
       "  'suivre',\n",
       "  'insulter',\n",
       "  'salir',\n",
       "  'corps',\n",
       "  'coller',\n",
       "  'abuser',\n",
       "  'indicible',\n",
       "  'continue',\n",
       "  'harcèlement',\n",
       "  'sifflet',\n",
       "  'propos',\n",
       "  'salace',\n",
       "  'remarque',\n",
       "  'tenue',\n",
       "  'jamais'],\n",
       " ['violence',\n",
       "  'femme',\n",
       "  'payet',\n",
       "  'transport',\n",
       "  'plaît',\n",
       "  'laissez',\n",
       "  'victime',\n",
       "  'seul',\n",
       "  'ignorez',\n",
       "  'agression',\n",
       "  'isme',\n",
       "  'quotidien'],\n",
       " ['suivre',\n",
       "  'sortie',\n",
       "  'métro',\n",
       "  'saison',\n",
       "  'épisod',\n",
       "  'cru',\n",
       "  'naïvement',\n",
       "  'temps',\n",
       "  'changer',\n",
       "  'donne',\n",
       "  'idée',\n",
       "  'minijupe'],\n",
       " ['ballot',\n",
       "  'homme',\n",
       "  'agresse',\n",
       "  'sexuellement',\n",
       "  'policier',\n",
       "  'charger',\n",
       "  'agression',\n",
       "  'sexuel',\n",
       "  'transport',\n",
       "  'masturber',\n",
       "  'condamner',\n",
       "  'mois',\n",
       "  'prison',\n",
       "  'sursis'],\n",
       " ['rine',\n",
       "  'millet',\n",
       "  'libertin',\n",
       "  'droit',\n",
       "  'majorité',\n",
       "  'marre',\n",
       "  'femme',\n",
       "  'prendre',\n",
       "  'métro',\n",
       "  'rine',\n",
       "  'deneuve',\n",
       "  'part',\n",
       "  'aller',\n",
       "  'césar',\n",
       "  'majorité'],\n",
       " ['gauchiste',\n",
       "  'train',\n",
       "  'retard',\n",
       "  'écolo',\n",
       "  'noyauter',\n",
       "  'parlement',\n",
       "  'européen',\n",
       "  'ville',\n",
       "  'paris',\n",
       "  'denis',\n",
       "  'baupin',\n",
       "  'incompéter',\n",
       "  'notoire',\n",
       "  'transports',\n",
       "  'bagage',\n",
       "  'militantisme',\n",
       "  'grâce',\n",
       "  'mauvais',\n",
       "  'raison'],\n",
       " ['temps',\n",
       "  'petit',\n",
       "  'monde',\n",
       "  'art',\n",
       "  'pou',\n",
       "  'voir',\n",
       "  'arrêtent',\n",
       "  'trouver',\n",
       "  'excuse',\n",
       "  'relation',\n",
       "  'commettre',\n",
       "  'bus',\n",
       "  'sex',\n",
       "  'uel',\n",
       "  'viol',\n",
       "  'justice',\n",
       "  'supprime',\n",
       "  'prescription',\n",
       "  'acte',\n",
       "  'ignoble',\n",
       "  'nioublini',\n",
       "  'pardon'],\n",
       " ['temps',\n",
       "  'justice',\n",
       "  'rendre',\n",
       "  'imprescriptible',\n",
       "  'bus',\n",
       "  'sex',\n",
       "  'uel',\n",
       "  'viol',\n",
       "  'victime',\n",
       "  'enfant',\n",
       "  'adult',\n",
       "  'nioublini',\n",
       "  'pardon',\n",
       "  'révélation',\n",
       "  'adèlehaenel',\n",
       "  'affaire',\n",
       "  'polanski',\n",
       "  'clap',\n",
       "  'fin',\n",
       "  'impunité',\n",
       "  'télérama',\n",
       "  'ion',\n",
       "  'dadele',\n",
       "  'haenel',\n",
       "  'polanski'],\n",
       " ['femme',\n",
       "  'militer',\n",
       "  'création',\n",
       "  'homme',\n",
       "  'regrette',\n",
       "  'âge',\n",
       "  'rencontrer',\n",
       "  'main',\n",
       "  'baladeuser',\n",
       "  'métro',\n",
       "  'affirme',\n",
       "  'rine',\n",
       "  'millet',\n",
       "  'répondre',\n",
       "  'aurelifil',\n",
       "  'cesidée']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda3b4fe0d057834456b5ea594cd377cf99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
