{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import spacy\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('_outputs/harassement_clean_french_no_bots.pickle')\n",
    "# df = pd.read_pickle('_outputs/harassement_clean_french_no_bots_transports.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_pos_tags = [\"PROP\",\"DET\",\"PART\",\"CCONJ\",\"ADP\",\"PRON\",\"VERB\",\"ADJ\"]\n",
    "noisy_pos_tags = [\"PROP\",\"DET\",\"PART\",\"CCONJ\",\"ADP\",\"PRON\"]\n",
    "MIN_TOKEN_LENGTH = 3 # minimum token length to remove\n",
    "MIN_WORDS_NUMBER = 10 # minimum of words\n",
    "\n",
    "# Importe le corpus Français\n",
    "import fr_core_news_sm\n",
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noise(token):\n",
    "    '''\n",
    "    standard way to validate spacy tokens\n",
    "    This method validate all the passed tokens and set true false on it\n",
    "    '''\n",
    "    is_noise = False\n",
    "    if token.pos_ in noisy_pos_tags:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_stop == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_digit == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_punct == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_space == True:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif token.is_alpha == False:\n",
    "        is_noise = True\n",
    "        \n",
    "    elif len(token.string) <= MIN_TOKEN_LENGTH:\n",
    "        is_noise = True\n",
    "        \n",
    "    return is_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_stop_words = get_stop_words('fr')\n",
    "for stop in fr_stop_words:\n",
    "    nlp.vocab[stop].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarque : c'est déjà partiellement nettoyé dans 01_clean_text\n",
    "# je garde pour la \"portabilité\" des fonctions\n",
    "def remove_specific_stop(words):\n",
    "    my_stop_words = ['balance', 'ton', 'porc', 'metoo', 'balancetonporc', 'via', 'hashtag', 'too', 'html', 'php', 'the', 'and', 'this', 'new', 'news']\n",
    "    for bad in my_stop_words:\n",
    "        words = words.replace(bad, ' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "70000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "index = 1\n",
    "for index, row in df.iterrows():\n",
    "    article = []\n",
    "    if index%10000 == 0:\n",
    "        print(index) # pour voir où cela en est\n",
    "    index += 1\n",
    "    words = row['clean_text']\n",
    "    words = remove_specific_stop(words)\n",
    "    if(len(words.split()) >= MIN_WORDS_NUMBER): # Only tweets with at least 10 words\n",
    "        nlp_words = nlp(words)\n",
    "        for word in nlp_words:\n",
    "            if not is_noise(word):\n",
    "                article.append(word.lemma_)\n",
    "        texts.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"_outputs/tokens.pickle\", \"wb\") as fp:\n",
    "# with open(\"_outputs/tokens_transports.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rappel',\n",
       "  'règle',\n",
       "  'homme',\n",
       "  'blanc',\n",
       "  'sexagénaire',\n",
       "  'finir',\n",
       "  'harceleur',\n",
       "  'occulter',\n",
       "  'autant',\n",
       "  'plausible',\n",
       "  'existence',\n",
       "  'tramway',\n",
       "  'désir'],\n",
       " ['histoire',\n",
       "  'malheureusement',\n",
       "  'réelle',\n",
       "  'digne',\n",
       "  'hollywood',\n",
       "  'coup',\n",
       "  'hope',\n",
       "  'reaction',\n",
       "  'from',\n",
       "  'ano',\n",
       "  'leader',\n",
       "  'from',\n",
       "  'movement',\n",
       "  'tim',\n",
       "  'assume',\n",
       "  'your',\n",
       "  'value',\n",
       "  'honor',\n",
       "  'one',\n",
       "  'outside',\n",
       "  'from'],\n",
       " ['juillet',\n",
       "  'gouvernement',\n",
       "  'baisser',\n",
       "  'budget',\n",
       "  'droit',\n",
       "  'femme',\n",
       "  'déjà',\n",
       "  'petit',\n",
       "  'budget',\n",
       "  'etat',\n",
       "  'appel',\n",
       "  'avft',\n",
       "  'bcp',\n",
       "  'moyen',\n",
       "  'mettre',\n",
       "  'place',\n",
       "  'face',\n",
       "  'onner'],\n",
       " ['autant',\n",
       "  'adhérer',\n",
       "  'autant',\n",
       "  'réserver',\n",
       "  'semantiqu',\n",
       "  'important',\n",
       "  'français',\n",
       "  'esprit',\n",
       "  'vengeance',\n",
       "  'souhaité',\n",
       "  'libération',\n",
       "  'justice'],\n",
       " ['racist',\n",
       "  'esclavagelybie',\n",
       "  'usul',\n",
       "  'man',\n",
       "  'esclavage',\n",
       "  'mafia',\n",
       "  'sarkosy',\n",
       "  'bhl',\n",
       "  'cameron',\n",
       "  'clin',\n",
       "  'soro',\n",
       "  'juppé',\n",
       "  'bye',\n",
       "  'khadafi',\n",
       "  'tué',\n",
       "  'chao'],\n",
       " ['mère',\n",
       "  'trint',\n",
       "  'ignant',\n",
       "  'aimer',\n",
       "  'simplement',\n",
       "  'fille',\n",
       "  'savoir',\n",
       "  'monde',\n",
       "  'planter',\n",
       "  'couteau',\n",
       "  'femme',\n",
       "  'merveilleux'],\n",
       " ['gauguin',\n",
       "  'drogue',\n",
       "  'jeune',\n",
       "  'fille',\n",
       "  'an',\n",
       "  'violer',\n",
       "  'sodomiser',\n",
       "  'ensuite'],\n",
       " ['jamais',\n",
       "  'défendre',\n",
       "  'mouvement',\n",
       "  'tenté',\n",
       "  'transformer',\n",
       "  'affaire',\n",
       "  'affaire',\n",
       "  'ramadan'],\n",
       " ['rencontre',\n",
       "  'intime',\n",
       "  'tuer',\n",
       "  'démon',\n",
       "  'projeté',\n",
       "  'extérieur',\n",
       "  'justice',\n",
       "  'moyen',\n",
       "  'monde',\n",
       "  'société',\n",
       "  'contrôle',\n",
       "  'total',\n",
       "  'efficace',\n",
       "  'agir',\n",
       "  'cause',\n",
       "  'intime',\n",
       "  'relier',\n",
       "  'singulier',\n",
       "  'magi',\n",
       "  'strat'],\n",
       " ['aller',\n",
       "  'assister',\n",
       "  'révolution',\n",
       "  'social',\n",
       "  'consentement',\n",
       "  'minorité',\n",
       "  'femme',\n",
       "  'homme',\n",
       "  'éclairer',\n",
       "  'occuper',\n",
       "  'pedophile',\n",
       "  'violeur',\n",
       "  'mass',\n",
       "  'complice',\n",
       "  'ferme',\n",
       "  'oeil']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda3b4fe0d057834456b5ea594cd377cf99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
